---
title: \vspace{3in} Proyecto Final Fundamentos de Estadística - Detección de fraudes
author: \vspace{3in} Abraham Nieto 51556 y Alejandro Hernández 87806
date: \vspace{2in} Diciembre 2018
output: pdf_document
toc: true
header-includes:
  \renewcommand{\contentsname}{Índice}

---
\newpage
```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
#-Working directory-
library(tidyverse)
library(readr)
library(stringr)
library(lubridate)
library(ggplot2)
library(Amelia)
library(R2jags)
frax<-read.csv("/home/abraham/FE2018/proyfin/d4a_fraud_data.csv",header = TRUE)
frax<-frax%>%select(gender,state,cardholder,balance,numTrans,numIntlTrans,creditLine,fraudRisk)
head(frax)
```

# Introducción

La detección de fraude es uno de los eventos más difíciles de detectar debido a que los fraudes son eventos de baja densidad; es decir, si planteamos el evento de fraude de forma binaria, 0 (no es fraude) y 1 (sí es fraude), la proporción de 1's con respecto a los 0's es sigificativamente menor. Otra forma de representarlo es que tenemos un problema de clases no balanceadas lo cual hace difícil encontrar el evento de interés que en este caso es el fraude.

En los datos que analizaremos en el presente trabajo, la variable respuesta binaria, fraudRisk tiene media 0.0658, lo que significa que la densidad de fraudes en la base es casi de un 6.6%, lo que significa que para encontrar un caso de fraude tendríamos que revisar al menos 15 registros, esto suponiendo que los revisamos al azar.

Entonces el objetivo es calcular la propensión de que a cada cliente le hayan hecho fraude, para esto debemos comenzar analizando las distintas variables y encontrar aquellas que nos puedan  servir para discriminar los casos de fraude.

Posteriormente, generaremos diversos modelos de clasificación y determinaremos la métrica adecuada para la selección del modelo óptimo.


# Análisis Exploratorio

A continuación presentamos un "summary" de los datos:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
summary(frax)

```

De inicio notamos que todas las variables son numéricas enteras, en distintas escalas. Se cuenta con información del genero (1 para hombre y 2 para mujer), el estado de EUA donde reside el cliente (1 a 54), cardholder (1 titular y 2 adicional), balance de la cuenta (0 a 30344), número de transacciones nacionales (0 a 100), número de transacciones internacionales (0 a 60), línea de crédito (1 a 75) y riesgo de fraude (1 sí y 0 no).

Primero realizamos un mapa de la información para detectar si existen valores ausentes en la base que debamos imputar, lo cual no es necesario ya que el mapa muestra que no existen valores ausentes.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
missmap(frax)
```

Revisando la variable balance contra la variable respuesta fraudRisk notamos que los casos de fraude se dan el 75% de las veces donde los saldos de los clientes son mayores a 7500 USD aproximadamente, mientras que en caso negativo este saldo se encuentra en la cuarta parte de los clientes. Con lo anterior, resulta claro que esta variable funciona para contrastar los casos.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=balance)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("fraudRisk")+theme_minimal()
```

Por otro lado, analizando la variable numTrans (Número de transacciones domésticas en un periodo dado) en contraste con la variable respuesta fraudRisk apreciamos que los casos de fraude se dan el 50% de las veces donde el cliente tiene más de 50 transacciones y en los casos negativos este número de transacciones aparece en menos del 75% de los casos.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=numTrans)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("fraudRisk")+theme_minimal()
```

Para la variable creditLine en contraste con la variable respuesta fraudRisk, apreciamos que los casos de fraude se dan el 50% de las veces donde el clinte tiene aproximadamente una línea de crédito de 20 y en los casos negativos el 75% de los casos tiene una linea de credito de 10.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=creditLine)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+theme_minimal()+xlab("fraudRisk")
```

Por su parte, la variable numIntlTrans en contraste con la variable respuesta fraudRisk vemos que la distribución es casi igual lo cual nos dice que la variable no sirve para discriminar las clases de fraude.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=numIntlTrans)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("fraudRisk")+theme_minimal()
```


Notamos que el riesgo de fraude es bastante más alto en hombres que mujeres.


```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(gender), fill=as.character(fraudRisk))) +
  geom_bar() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("gender")+theme_minimal()
```



La distinción entre los posibles valores de la variable fraudRisk se aprecia de manera más adecuada cuando se trata del titular de la tarjeta.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=creditLine)) +
  geom_boxplot() + facet_grid(~as.character(cardholder))+
  scale_fill_manual(values=c("darkcyan", "magenta")) +xlab("fraudRisk")+theme_minimal()
```

Notamos que las correlaciones más altas con respecto a la variable respuesta se dan con las variables balance, creditLine y numTrans.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
library(corrplot)
M <- cor(frax)
corrplot(M, method = "circle")
```


# Segmentos

De acuerdo con los comentarios del profesor vamos a segmentar con base en las variables balance y tipo de línea de crédito.

Primero segmentamos la variable balance como sigue:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
library(Hmisc)
x <- frax$balance  # some data
quintiles <- quantile(x, probs=seq(0.2, 1, by = 0.2))
new<-cut(x, quintiles, ordered = TRUE,label=1:4)#quantile(x,quintiles)
new[is.na(new)] <- 1
frax$balance_q<-new

quint1<-cut2(frax$balance,g=5)
tab_quint1<-table(quint1)

tab_quint_b<-cbind(c("[0,2822)",names(tab_quint1[3:5])),c(sum(tab_quint1[1:2]),tab_quint1[3:5]))
colnames(tab_quint_b)<-c("segmento","no. clientes")
rownames(tab_quint_b)<-c(1:4)

```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
library(dplyr)
tab_bal<-frax%>%group_by(balance_q)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),total_f=sum(fraudRisk))%>%
  mutate(proporcion_f=round(total_f/sum(total_f)*100,2),proporcion_ctes=round(ctes/sum(ctes)*100,2))

tab_bal<-cbind(tab_quint_b[,1],tab_bal)
tab_bal<-tab_bal %>% select(c(2,1,3,4,5,6,7))
names(tab_bal)[2]<-"segmento"
tab_bal
```
Después de segmentar la variable balance en cuatro grupos podemos observar con la ayuda de la tabla anterior que el 73% del fraude se concentra en el segmento 4 que contiene tan solo el 18% de los clientes, recordar que el segmento 4 son aquellos clientes con un balance mayor a los 7 mil dólares, también es importante notar que la tasa de fraude en este segmento es de más del 24%, lo que nos indica que es 4 veces mayor a la densidad original que es del 6%.

Ahora segmentamos la variable creditLine como sigue:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
x <- frax$creditLine  # some data
quintiles2 <- quantile(x, probs=seq(0, 1, by = 0.25))
new2<-cut(x, quintiles2, ordered = TRUE,label=1:4)#quantile(x,quintiles)
new2[is.na(new2)] <- 1
frax$credl_q<-new2

quint2<-cut2(frax$creditLine,g=4)
tab_quint2<-table(quint2)
```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
tab_cred<-frax%>%group_by(credl_q)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),total_f=sum(fraudRisk))%>%
  mutate(proporcion_f=round(total_f/sum(total_f)*100,2),proporcion_ctes=round(ctes/sum(ctes)*100,2))

tab_cred<-cbind(names(tab_quint2),tab_cred)
tab_cred<-tab_cred %>% select(c(2,1,3,4,5,6,7))
names(tab_cred)[2]<-"segmento"
tab_cred
```

Haciendo 4 segmentos en los tipos de líneas de créditos podemos observar que el segemento 4 que se refiere del tipo 12 en adelante contiene el 70% de los clientes fraudulentos y representa casi el 23% de los clientes totales, además la tasa de fraude en este segmento es del 18.7% lo cual es más de 3 veces mayor que la densidad original de de 6% entonces es 3 veces más probable que haya clientes o casos de fraude en este segmento, por otro lado dentro de la segementación de esta varible el segmento 3 que representa los tipos entre 6 y 11  tiene una tasa de fraude de 4.76% la cual es menor que la densidad original al iguial que los segmentos 1 y 2 con tasas de fraude de .82% y 2.05% respectivamente.

Ahora dado que nuestro objetivo es construir un modelo de propensión de fraude mezclamos los segmentos de ambas variables de tal forma que para tener mayor asertividad en la propensión se tenga un modelo para cada segmento utilizando el resto de las variables como explicativas.

Cruzando los distintos segmentos tenemos los siguientes resultados:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=balance)) +
  geom_boxplot() + facet_grid(~credl_q)+
  scale_fill_manual(values=c("darkcyan", "magenta")) + xlab("fraudRisk")+theme_minimal()
```

Si observamos los diagramas de caja y brazos de los 4 segmentos de los tipos de lineas de crédito a través de su balance o saldo vemos que para el segmento 4 la diferencia entre las distribuciones de balance de los casos de fraude y no fraude se diferencian de forma muy clara, lo cual hace pensar que en este segmento sería más sencillo encontrar un modelo que discrimine a los cientes más propensos a ser casos de fraude, en los primeros 2 segmentos pudiera ser más complejo dado que las cajas se traslapan.


Análizando los segmentos mezclados de las variables balance y creditLine tenemos lo siguiente:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
seg<-frax%>%group_by(balance_q,credl_q)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),
                                               total_f=sum(fraudRisk))
seg%>%mutate(proporcion_f=round(total_f/6058*100,2),
proporcion_ctes=round(ctes/100000*100,2))%>%arrange(desc(proporcion_f))

```

El segmento (4,4) (balance,creditLine) contiene el 58% de los casos de fraude mientras que su densidad de fraude es de 38.43%, este segemento es donde de manera más sencilla se pueden encontrar los casos fruadulentos, luego los segmentos (4,3) y (3,4) representan casi el 21% del total de los casos de fraude con una tasa de casos de fraude de más del 10% es decir con estos 3 segmentos se cubre casi el 79% de los casos fraudulentos, lo que estamos haciendo con estos cruces de segmentos es crear categorías de mayor a menor "facilidad" para detectar los casos, entonces la idea es que los modelos que construyamos encuentren probabilidades más asertivas en estos 2 segementos y obviamente mucho menores en el resto de ellos.
En términos de negocio queremos encontrar  3 tipos de segmentos, digamos alto, medio y bajo donde podamos saber que la probabilidad de encontrar casos de fraude va de mayor a menor, de tal forma que podamos atacar este problema de detección en cada uno de ellos.

Por tanto, se definen los siguientes segmentos:

- Alto= {segmento (4,4)}

- Medio={segmento (4,3), segmento (3,4)}

- Bajo={todos los segmentos}-{Alto,Medio}

```{r,message=FALSE,warning=FALSE,echo=FALSE}
frax$Segmento<-ifelse(frax$balance_q==4 & frax$credl_q==4,"Alto",
                      ifelse(as.numeric(frax$balance_q)*as.numeric(frax$credl_q)==12,"Medio","Bajo"))
```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
frax%>%group_by(Segmento)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),total_f=sum(fraudRisk))%>%
  mutate(proporcion_f=round(total_f/sum(total_f)*100,2),proporcion_ctes=round(ctes/sum(ctes)*100,2))
```
Finalmente con estos 3 segmentos podemos observar que para el segmento Alto se detecta el 58% delos casos de fraude analizando sólo el 9% de los clientes, para el Medio se detecta el 21% de los fraudes con el 12.2% de los clientes ambos con densidades o tasas de fraude mayores a la original, para el segmento más bajo tiene una densidad del 1.6%.

# Modelos jerárquicos

En primera instancia, cabe destacar que convertimos a dummys las variables "gender"" y "cardholder".

El Segmento lo definimos como Alto=1, Medio=2 y Bajo=3. 

Asimismo, no se contemplo la variable "state" ya que al considerarla en el problema jerárquico hacia que fuera muy complejo su cómputo.

Finalmente, se segmentó la muestra en 70% entrenamiento y 30% de prueba.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
frax$gender[which(frax$gender==2)]=0
frax$cardholder[which(frax$cardholder==2)]=0
frax$Segmento[which(frax$Segmento=="Alto")]=1
frax$Segmento[which(frax$Segmento=="Medio")]=2
frax$Segmento[which(frax$Segmento=="Bajo")]=3
```

## Modelo beta-bernoulli

El modelo se especificó como sigue:

$$ Y_i \sim Ber(p_{ij}) $$


$$p_j \sim Beta(a,b)  $$
$$a,b \sim gama(0.01,0.01)  $$



```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
fraude_jerarquico3 <- '
model
{
#Verosimilitud
for (i in 1:n) {
	y[i] ~ dbern(p[seg[i]])
}
#Priors 
for (j in 1:m) { p[j] ~ dbeta(a,b) }
a ~ dgamma(0.01,0.01)
b ~ dgamma(0.01,0.01)
#Predicción
for (i in 1:n) { yf1[i] ~ dbern(p[seg[i]]) }
#Parametro de interés
eta <- a/(a+b)
}
'
cat(fraude_jerarquico3, file = 'fraude_jerarquico3')
n<-dim(frax)[1]
m<-length(unique(frax$Segmento))

#-Defining data-
data<-list("n"=n,"m"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento)

#-Defining inits-
inits<-function(){list(p=rep(0.5,m),a=1,b=1,yf1=rep(0,n))}

#-Selecting parameters to monitor-
parameters<-c("p","eta","yf1")


modelo_jer3<-jags(data,inits,parameters,model.file="fraude_jerarquico3",
                n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

Clasificación global:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
out.sum.jer3<-modelo_jer3$BUGSoutput$summary

#Predictions
out.yf.jer3<-out.sum.jer3[grep("yf1",rownames(out.sum.jer3)),]
base_graf.jer3<-as.data.frame(cbind(frax,out.yf.jer3[,c(1,3,7)])) 
prop.table(table(base_graf.jer3$fraudRisk,round(base_graf.jer3$mean)),2)
```


Clasificación por segmento:

Alto:
```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto3<-filter(base_graf.jer3,Segmento==1)
prop.table(table(alto3$fraudRisk,round(alto3$mean)),2)

```

Medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio3<-filter(base_graf.jer3,Segmento==2)
prop.table(table(medio3$fraudRisk,round(medio3$mean)),2)
```

Bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo3<-filter(base_graf.jer3,Segmento==3)
prop.table(table(bajo3$fraudRisk,round(bajo3$mean)),2)
```

Notamos que este modelo da resultados muy malos, pues en terminos generales la sensibilidad es del 33%, por su parte para los segmentos medio y bajo no está clasificando ningun fraude, lo cual no es apropiado.

## Modelo lineal generalizado con efectos independientes

El modelo de efectos constantes se especificó de la siguiente forma:


$$ Y_i \sim Ber(p_i) $$


$$ logit(p_i)=\alpha_{ij}+\beta_{1j}genero_{ij}+\beta_{2j}cardholder_{ij}+ \beta_{3j}balance_{ij}+\beta_{4j}numTrans_{ij}+\beta_{5j}numIntTrans_{ij}+\beta_{6j}creditline_{ij} $$


Donde:


$$\alpha_j\sim N(0,0.001) $$

$$\beta_j\sim N(0,0.001) $$





con $j=1, 2, 3$ los segmentos Alto=1, Medio=2 y Bajo=3.


```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
fraude_jerarquico0 <- '
model
{
#Verosimilitud
for (i in 1:n){
	y[i] ~ dbern(p[i])
	logit(p[i])<-alpha[seg[i]]+beta1[seg[i]]*x1[1]+beta2[seg[i]]*x2[i]+beta3[seg[i]]*x3[i]+beta4[seg[i]]*x4[i]+beta5[seg[i]]*x5[i]+beta6[seg[i]]*x6[i]
}
#Priors 
for (j in 1:m){ 
  alpha[j] ~ dnorm(0,0.001)
  beta1[j] ~ dnorm(0,0.001)
  beta2[j] ~ dnorm(0,0.001)
  beta3[j] ~ dnorm(0,0.001)
  beta4[j] ~ dnorm(0,0.001)
  beta5[j] ~ dnorm(0,0.001)
  beta6[j] ~ dnorm(0,0.001)
}

#Predicción
for (i in 1:n) { yf1[i] ~ dbern(p[i]) }

}
'
cat(fraude_jerarquico0, file = 'fraude_jerarquico0')
n<-dim(frax)[1]
m<-length(unique(frax$Segmento))

#-Defining data-
data<-list("n"=n,"m"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento,"x1"=frax$gender,"x2"=frax$cardholder,"x3"=frax$balance,"x4"=frax$numTrans,"x5"=frax$numIntlTrans,"x6"=frax$creditLine)

#-Defining inits-
inits<-function(){list(alpha=rep(0,m),beta1=rep(0,m),beta2=rep(0,m),beta3=rep(0,m),beta4=rep(0,m),beta5=rep(0,m),beta6=rep(0,m),yf1=rep(1,n))}

#-Selecting parameters to monitor-
parameters<-c("p","alpha","beta1","beta2","beta3","beta4","beta5","beta6","yf1")


modelo_jer0<-jags(data,inits,parameters,model.file="fraude_jerarquico0",
                n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

Revisamos que todas las cadenas se estabilizaran y que no hubiera problemas de autocorrelación.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
# Graficas para ver comportamiento de los parametros estimados

out.jer0<-modelo_jer0$BUGSoutput$sims.list

# Para alpha1
alpha<-out.jer0$alpha[,1]
par(mfrow=c(2,2))
plot(alpha,type="l")
plot(cumsum(alpha)/(1:length(alpha)),type="l")
hist(alpha,freq=FALSE)
acf(alpha)

# Para alpha2
alpha2<-out.jer0$alpha[,2]
par(mfrow=c(2,2))
plot(alpha2,type="l")
plot(cumsum(alpha2)/(1:length(alpha2)),type="l")
hist(alpha2,freq=FALSE)
acf(alpha2)

# Para alpha3
alpha3<-out.jer0$alpha[,3]
par(mfrow=c(2,2))
plot(alpha3,type="l")
plot(cumsum(alpha3)/(1:length(alpha3)),type="l")
hist(alpha3,freq=FALSE)
acf(alpha3)

#Para beta1.1
beta1.1<-out.jer0$beta1[,1]
par(mfrow=c(2,2))
plot(beta1.1,type="l")
plot(cumsum(beta1.1)/(1:length(beta1.1)),type="l")
hist(beta1.1,freq=FALSE)
acf(beta1.1)

#Para beta1.2
beta1.2<-out.jer0$beta1[,2]
par(mfrow=c(2,2))
plot(beta1.2,type="l")
plot(cumsum(beta1.2)/(1:length(beta1.2)),type="l")
hist(beta1.2,freq=FALSE)
acf(beta1.2)

#Para beta1.3
beta1.3<-out.jer0$beta1[,3]
par(mfrow=c(2,2))
plot(beta1.3,type="l")
plot(cumsum(beta1.3)/(1:length(beta1.3)),type="l")
hist(beta1.3,freq=FALSE)
acf(beta1.3)

```

A continuación realizamos una tabla para ver que tan bien clasificó los fraudes nuestro modelo:


```{r,message=FALSE,warning=FALSE,echo=FALSE}
out.sum.jer0<-modelo_jer0$BUGSoutput$summary

#Predictions
out.yf.jer0<-out.sum.jer0[grep("yf1",rownames(out.sum.jer0)),]
base_graf.jer0<-as.data.frame(cbind(frax,out.yf.jer0[,c(1,3,7)])) 
prop.table(table(base_graf.jer0$fraudRisk,round(base_graf.jer0$mean)),2)
```

Notamos que la sensibilidad no es de lo más adecuada, pues es del 75%.

Ahora veremos el efecto por cada segmento:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto<-filter(base_graf.jer0,Segmento==1)
prop.table(table(alto$fraudRisk,round(alto$mean)),2)

```
La tabla anterior nos muestra la clasificación para el segmento alto.

Ahora veamos el segmento medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio<-filter(base_graf.jer0,Segmento==2)
prop.table(table(medio$fraudRisk,round(medio$mean)),2)
```

Finalmente, para el segmento bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo<-filter(base_graf.jer0,Segmento==3)
prop.table(table(bajo$fraudRisk,round(bajo$mean)),2)
```

El resultado es el esperado, pues el segmento alto es el que tiene la mejor sensibilidad debido a que es el segmento con mayor número de fraudes, por lo que la clasificación dentro de dicho segmento es más adecuada.

## Modelo lineal generalizado con efectos intercambiables


El modelo lo especificamos como sigue:

$$ Y_i \sim Ber(p_i) $$


$$ logit(p_i)=\alpha_{ij}+\beta_{1j}genero_{ij}+\beta_{2j}cardholder_{ij}+ \beta_{3j}balance_{ij}+\beta_{4j}numTrans_{ij}+\beta_{5j}numIntTrans_{ij}+\beta_{6j}creditline_{ij} $$


Donde:


$$\alpha_j\sim N(0,\tau) $$

$$\beta_j\sim N(0,\tau) $$


$$\tau\sim Gama(0.001,0.001) $$


con $j=1, 2, 3$ los segmentos Alto=1, Medio=2 y Bajo=3.



```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
fraude_jerarquico1 <- '
model
{
#Verosimilitud
for (i in 1:n){
	y[i] ~ dbern(p[i])
	logit(p[i])<-alpha[seg[i]]+beta1[seg[i]]*x1[1]+beta2[seg[i]]*x2[i]+beta3[seg[i]]*x3[i]+beta4[seg[i]]*x4[i]+beta5[seg[i]]*x5[i]+beta6[seg[i]]*x6[i]
}
#Priors 
for (j in 1:m){ 
  alpha[j] ~ dnorm(0,tau)
  beta1[j] ~ dnorm(0,tau)
  beta2[j] ~ dnorm(0,tau)
  beta3[j] ~ dnorm(0,tau)
  beta4[j] ~ dnorm(0,tau)
  beta5[j] ~ dnorm(0,tau)
  beta6[j] ~ dnorm(0,tau)
}
# Hyperprior
tau ~ dgamma(0.001,0.001)


#Predicción
for (i in 1:n) { yf1[i] ~ dbern(p[i]) }

}
'
cat(fraude_jerarquico1, file = 'fraude_jerarquico1')
n<-dim(frax)[1]
m<-length(unique(frax$Segmento))

#-Defining data-
data<-list("n"=n,"m"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento,"x1"=frax$gender,"x2"=frax$cardholder,"x3"=frax$balance,"x4"=frax$numTrans,"x5"=frax$numIntlTrans,"x6"=frax$creditLine)

#-Defining inits-
inits<-function(){list(alpha=rep(0,m),beta1=rep(0,m),beta2=rep(0,m),beta3=rep(0,m),beta4=rep(0,m),beta5=rep(0,m),beta6=rep(0,m),a=1,b=1,yf1=rep(1,n))}

#-Selecting parameters to monitor-
parameters<-c("p","alpha","beta1","beta2","beta3","beta4","beta5","beta6","yf1")


modelo_jer1<-jags(data,inits,parameters,model.file="fraude_jerarquico1",
                n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

En este caso también las cadenas covergen de forma adecuada aún con pocas iteraciones como se aprecia en las siguientes gráficas para $\alpha_j$ y $\beta_{1j}$



```{r,message=FALSE,warning=FALSE,echo=FALSE}
# Graficas para ver comportamiento de los parametros estimados

out.jer1<-modelo_jer1$BUGSoutput$sims.list

# Para alpha1
alpha<-out.jer1$alpha[,1]
par(mfrow=c(2,2))
plot(alpha,type="l")
plot(cumsum(alpha)/(1:length(alpha)),type="l")
hist(alpha,freq=FALSE)
acf(alpha)

# Para alpha2
alpha2<-out.jer1$alpha[,2]
par(mfrow=c(2,2))
plot(alpha2,type="l")
plot(cumsum(alpha2)/(1:length(alpha2)),type="l")
hist(alpha2,freq=FALSE)
acf(alpha2)

# Para alpha3
alpha3<-out.jer1$alpha[,3]
par(mfrow=c(2,2))
plot(alpha3,type="l")
plot(cumsum(alpha3)/(1:length(alpha3)),type="l")
hist(alpha3,freq=FALSE)
acf(alpha3)

#Para beta1.1
beta1.1<-out.jer1$beta1[,1]
par(mfrow=c(2,2))
plot(beta1.1,type="l")
plot(cumsum(beta1.1)/(1:length(beta1.1)),type="l")
hist(beta1.1,freq=FALSE)
acf(beta1.1)

#Para beta1.2
beta1.2<-out.jer1$beta1[,2]
par(mfrow=c(2,2))
plot(beta1.2,type="l")
plot(cumsum(beta1.2)/(1:length(beta1.2)),type="l")
hist(beta1.2,freq=FALSE)
acf(beta1.2)

#Para beta1.3
beta1.3<-out.jer1$beta1[,3]
par(mfrow=c(2,2))
plot(beta1.3,type="l")
plot(cumsum(beta1.3)/(1:length(beta1.3)),type="l")
hist(beta1.3,freq=FALSE)
acf(beta1.3)

```

De igual manera realizamos una tabla para la clasificación:



```{r,message=FALSE,warning=FALSE,echo=FALSE}
out.sum.jer1<-modelo_jer1$BUGSoutput$summary

#Predictions
out.yf.jer1<-out.sum.jer1[grep("yf1",rownames(out.sum.jer1)),]
base_graf.jer1<-as.data.frame(cbind(frax,out.yf.jer1[,c(1,3,7)])) 
prop.table(table(base_graf.jer1$fraudRisk,round(base_graf.jer1$mean)),2)
```

Notamos resultados muy similares al de efectos independientes; es decir, que nuestro modelo tiene una especificidad alta; no obstante, la sensibilidad de 75% es baja, pues el efecto de tener un fraude es muy relevante.

Ahora analizaremos la clasificación por cada segmento. Primero se muestra el segmento alto:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto1<-filter(base_graf.jer1,Segmento==1)
prop.table(table(alto1$fraudRisk,round(alto1$mean)),2)

```

Ahora veamos el segmento medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio1<-filter(base_graf.jer1,Segmento==2)
prop.table(table(medio1$fraudRisk,round(medio1$mean)),2)
```

Finalmente, para el segmento bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo1<-filter(base_graf.jer1,Segmento==3)
prop.table(table(bajo1$fraudRisk,round(bajo1$mean)),2)
```

El resultado anterior nuevamente resulta consistente, pues sabemos que en la categoría Alta al haber más fraudes, la predicción va a ser mejor. Por su parte, en las otras dos categorías como el porcentaje de fraudes es menor, no hay suficientes "exitos" para generar una buena predicción.

Como constatamos el modelo de efectos independientes y el de intercambiabilidad de "comparte" la mayor cantidad de información entre segmentos da resultados muy parecidos. 


# Conclusiones



# Referencias

- Notas de clase del profesor Juan Carlos Martínez Ovando, en particular lo referente a modelos jerarquicos y modelos de regresión.

- Gelman, A., Carlin, J. B., Stern, H. S. & Rubin, D. Bayesian Data Analysis, 2002, 2a edición. Chapman & Hall: Boca Raton. 

- Gelman, A., Hill, J. Data Analysis Using Regression and Multilevel / Hierarchical Models, 2008, 6a edición, Cambridge University Press. 




```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
modelo_jer.txt <-
'
model{
  for(t in 1:N){
    y[t] ~ dbern(theta[seg[t]])
  }
  for(j in 1:nCoins){
    theta[j] ~ dbeta(a, b)
  }
  a <- mu * kappa
  b <- (1 - mu) * kappa
  # A_mu = 2, B_mu = 2
  mu ~ dbeta(.1, .1)
  kappa ~ dgamma(1, 0.1)
}
'
cat(modelo_jer.txt, file = 'modelo_jer.txt')
N<-dim(frax)[1]
nCoins<-length(unique(frax$Segmento))

#-Defining data-
data<-list("N"=n,"nCoins"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento)

#-Defining inits-
jags.inits <- function(){
  list("mu" = runif(1, 0.1, 0.9),
    "kappa" = runif(1, 5, 20))
}
jags_fit <- jags(
  model.file = "modelo_jer.txt",    # modelo de JAGS
  inits = jags.inits,   # valores iniciales
  data = data,    # lista con los datos
  parameters.to.save = c("mu", "kappa", "theta"),  # parámetros por guardar
  n.chains = 2,   # número de cadenas
  n.iter = 200,    # número de pasos
  n.burnin = 50   # calentamiento de la cadena
  )

traceplot(jags_fit, varname = c("kappa", "mu", "theta"))


jags_fit

```