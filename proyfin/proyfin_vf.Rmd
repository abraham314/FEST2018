---
title: \vspace{3in} Detección de fraudes - Fundamentos de Estadística
author: \vspace{3in} Abraham Nieto 51556 y Alejandro Hernández 87806
date: \vspace{2in} Diciembre 2018
output: pdf_document
toc: true
header-includes:
  \renewcommand{\contentsname}{Índice}

---
\newpage
```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
#-Working directory-
library(tidyverse)
library(readr)
library(knitr)
library(stringr)
library(lubridate)
library(egg)
library(ggplot2)
library(Amelia)
library(R2jags)
library(gridExtra)
library(caret)
frax<-read.csv("d4a_fraud_data.txt",header = TRUE)
frax<-frax%>%select(gender,state,cardholder,balance,numTrans,numIntlTrans,creditLine,fraudRisk)
head(frax)
```

# Introducción

La detección de fraude es uno de los eventos más difíciles de detectar debido a que los fraudes son eventos de baja densidad; es decir, si planteamos el evento de fraude de forma binaria, 0 (no es fraude) y 1 (sí es fraude), la proporción de 1's con respecto a los 0's es sigificativamente menor. Otra forma de representarlo es que tenemos un problema de clases no balanceadas lo cual hace difícil encontrar el evento de interés que en este caso es el fraude.

En los datos que analizaremos en el presente trabajo, la variable respuesta binaria, fraudRisk tiene media 0.0658, lo que significa que la densidad de fraudes en la base es casi de un 6.6%, lo que significa que para encontrar un caso de fraude tendríamos que revisar al menos 15 registros, esto suponiendo que los revisamos al azar.

Entonces el objetivo es calcular la propensión de que a cada cliente le hayan hecho fraude, para esto debemos comenzar analizando las distintas variables y encontrar aquellas que nos puedan  servir para discriminar los casos de fraude.

Posteriormente, generaremos diversos modelos de clasificación y determinaremos la métrica adecuada para la selección del modelo óptimo.


# Análisis Exploratorio

A continuación presentamos un "summary" de los datos:


```{r ,message=FALSE,warning=FALSE,echo=FALSE}
as.table(summary(frax))
#kable(summary(frax),format="latex")
#kable(summary(frax[,5:8]))
#kable(summary(frax[,6:11]),format="latex")
```




Se cuenta con información del género (1 para hombre y 2 para mujer), el estado de EUA donde reside el cliente (1 a 54), cardholder (1 titular y 2 adicional), balance de la cuenta (0 a 30344), número de transacciones nacionales (0 a 100), número de transacciones internacionales (0 a 60), línea de crédito (1 a 75) y riesgo de fraude (1 sí y 0 no).

Primero realizamos un mapa de la información para detectar si existen valores ausentes en la base que debamos imputar, lo cual no es necesario ya que notamos que no existen valores ausentes.


Revisando la variable balance contra la variable respuesta fraudRisk notamos que los casos de fraude se dan el 75% de las veces donde los saldos de los clientes son mayores a 7500 USD aproximadamente, mientras que en caso negativo este saldo se encuentra en la cuarta parte de los clientes. Con lo anterior, resulta claro que esta variable funciona para contrastar los casos.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=balance)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("fraudRisk")+theme_minimal()
```

Por otro lado, analizando la variable numTrans (Número de transacciones domésticas en un periodo dado) en contraste con la variable respuesta fraudRisk apreciamos que los casos de fraude se dan el 50% de las veces donde el cliente tiene más de 50 transacciones y en los casos negativos este número de transacciones aparece en menos del 75% de los casos.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=numTrans)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("fraudRisk")+theme_minimal()
```

Para la variable creditLine en contraste con la variable respuesta fraudRisk, apreciamos que los casos de fraude se dan el 50% de las veces donde el cliente tiene aproximadamente una línea de crédito de 20 y en los casos negativos el 75% de los casos tiene una linea de credito de 10.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=creditLine)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+theme_minimal()+xlab("fraudRisk")
```

Por su parte, la variable numIntlTrans en contraste con la variable respuesta fraudRisk vemos que la distribución es casi igual lo cual nos dice que la variable no sirve para discriminar las clases de fraude.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=numIntlTrans)) +
  geom_boxplot() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("fraudRisk")+theme_minimal()
```


Notamos que el riesgo de fraude es bastante más alto en mujeres que en hombres, pues a pesar de que el número de mujeres es menor, el numero de fraudes que comente es similar al de los hombres.


```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(gender), fill=as.character(fraudRisk))) +
  geom_bar() +
  scale_fill_manual(values=c("darkcyan", "magenta"))+xlab("gender")+theme_minimal()
```



La distinción entre los posibles valores de la variable fraudRisk se aprecia de manera más adecuada cuando se trata del titular de la tarjeta.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=creditLine)) +
  geom_boxplot() + facet_grid(~as.character(cardholder))+
  scale_fill_manual(values=c("darkcyan", "magenta")) +xlab("fraudRisk")+theme_minimal()
```

Notamos que las correlaciones más altas con respecto a la variable respuesta se dan con las variables balance, creditLine y numTrans.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
library(corrplot)
M <- cor(frax)
corrplot(M, method = "circle")
```


# Segmentos

De acuerdo con los comentarios del profesor vamos a segmentar con base en las variables balance y tipo de línea de crédito.

Primero segmentamos la variable balance como sigue:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
library(Hmisc)
x <- frax$balance  # some data
quintiles <- quantile(x, probs=seq(0.2, 1, by = 0.2))
new<-cut(x, quintiles, ordered = TRUE,label=1:4)#quantile(x,quintiles)
new[is.na(new)] <- 1
frax$balance_q<-new

quint1<-cut2(frax$balance,g=5)
tab_quint1<-table(quint1)

tab_quint_b<-cbind(c("[0,2822)",names(tab_quint1[3:5])),c(sum(tab_quint1[1:2]),tab_quint1[3:5]))
colnames(tab_quint_b)<-c("segmento","no. clientes")
rownames(tab_quint_b)<-c(1:4)

```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
library(dplyr)
tab_bal<-frax%>%group_by(balance_q)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),total_f=sum(fraudRisk))%>%
  mutate(proporcion_f=round(total_f/sum(total_f)*100,2),proporcion_ctes=round(ctes/sum(ctes)*100,2))

tab_bal<-cbind(tab_quint_b[,1],tab_bal)
tab_bal<-tab_bal %>% select(c(2,1,3,4,5,6,7))
names(tab_bal)[2]<-"segmento"
kable(tab_bal)
```

Después de segmentar la variable balance en cuatro grupos podemos observar con la ayuda de la tabla anterior que el 73% del fraude se concentra en el segmento 4 que contiene tan solo el 18% de los clientes, recordar que el segmento 4 son aquellos clientes con un balance mayor a los 7 mil dólares, también es importante notar que la tasa de fraude en este segmento es de más del 24%, lo que nos indica que es 4 veces mayor a la densidad original que es del 6%.

Ahora segmentamos la variable creditLine como sigue:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
x <- frax$creditLine  # some data
quintiles2 <- quantile(x, probs=seq(0, 1, by = 0.25))
new2<-cut(x, quintiles2, ordered = TRUE,label=1:4)#quantile(x,quintiles)
new2[is.na(new2)] <- 1
frax$credl_q<-new2

quint2<-cut2(frax$creditLine,g=4)
tab_quint2<-table(quint2)
```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
tab_cred<-frax%>%group_by(credl_q)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),total_f=sum(fraudRisk))%>%
  mutate(proporcion_f=round(total_f/sum(total_f)*100,2),proporcion_ctes=round(ctes/sum(ctes)*100,2))

tab_cred<-cbind(names(tab_quint2),tab_cred)
tab_cred<-tab_cred %>% select(c(2,1,3,4,5,6,7))
names(tab_cred)[2]<-"segmento"
kable(tab_cred)
```

Haciendo 4 segmentos en los tipos de líneas de créditos podemos observar que el segemento 4 que se refiere del tipo 12 en adelante contiene el 70% de los clientes fraudulentos y representa casi el 23% de los clientes totales, además la tasa de fraude en este segmento es del 18.7% lo cual es más de 3 veces mayor que la densidad original de de 6% entonces es 3 veces más probable que haya clientes o casos de fraude en este segmento, por otro lado dentro de la segementación de esta varible el segmento 3 que representa los tipos entre 6 y 11  tiene una tasa de fraude de 4.76% la cual es menor que la densidad original al igual que los segmentos 1 y 2 con tasas de fraude de .82% y 2.05% respectivamente.

Ahora dado que nuestro objetivo es construir un modelo de propensión de fraude mezclamos los segmentos de ambas variables de tal forma que para tener mayor asertividad en la propensión se tenga un modelo para cada segmento utilizando el resto de las variables como explicativas.

Cruzando los distintos segmentos tenemos los siguientes resultados:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
ggplot(frax, aes(x=as.character(fraudRisk), y=balance)) +
  geom_boxplot() + facet_grid(~credl_q)+
  scale_fill_manual(values=c("darkcyan", "magenta")) + xlab("fraudRisk")+theme_minimal()
```

Si observamos los diagramas de caja y brazos de los 4 segmentos de los tipos de líneas de crédito a través de su balance o saldo vemos que para el segmento 4 la diferencia entre las distribuciones de balance de los casos de fraude y no fraude se diferencían de forma muy clara, lo cual hace pensar que en este segmento sería más sencillo encontrar un modelo que discrimine a los cientes más propensos a ser casos de fraude, en los primeros 2 segmentos pudiera ser más complejo dado que las cajas se traslapan.


Análizando los segmentos mezclados de las variables balance y creditLine tenemos lo siguiente:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
seg<-frax%>%group_by(balance_q,credl_q)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),
                                               total_f=sum(fraudRisk))
tab<-seg%>%mutate(proporcion_f=round(total_f/6058*100,2),
proporcion_ctes=round(ctes/100000*100,2))%>%arrange(desc(proporcion_f))
kable(tab)
```

El segmento (4,4) (balance,creditLine) contiene el 58% de los casos de fraude mientras que su densidad de fraude es de 38.43%, este segmento es donde de manera más sencilla se pueden encontrar los casos fruadulentos, luego los segmentos (4,3) y (3,4) representan casi el 21% del total de los casos de fraude con una tasa de casos de fraude de más del 10% es decir con estos 3 segmentos se cubre casi el 79% de los casos fraudulentos, lo que estamos haciendo con estos cruces de segmentos es crear categorías de mayor a menor "facilidad" para detectar los casos, entonces la idea es que los modelos que construyamos encuentren probabilidades más asertivas en estos 2 segmentos y obviamente mucho menores en el resto de ellos.
En términos de negocio queremos encontrar  3 tipos de segmentos, digamos alto, medio y bajo donde podamos saber que la probabilidad de encontrar casos de fraude va de mayor a menor, de tal forma que podamos atacar este problema de detección en cada uno de ellos.

Por tanto, se definen los siguientes segmentos:

- Alto= {segmento (4,4)}

- Medio={segmento (4,3), segmento (3,4)}

- Bajo={todos los segmentos}-{Alto,Medio}

```{r,message=FALSE,warning=FALSE,echo=FALSE}
frax$Segmento<-ifelse(frax$balance_q==4 & frax$credl_q==4,"Alto",
                      ifelse(as.numeric(frax$balance_q)*as.numeric(frax$credl_q)==12,"Medio","Bajo"))
```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
tab0<-frax%>%group_by(Segmento)%>%summarise(ctes=n(),tasa_f=round(mean(fraudRisk)*100,2),total_f=sum(fraudRisk))%>%
  mutate(proporcion_f=round(total_f/sum(total_f)*100,2),proporcion_ctes=round(ctes/sum(ctes)*100,2))
kable(tab0)
```

Finalmente con estos 3 segmentos podemos observar que para el segmento Alto se detecta el 58% delos casos de fraude analizando sólo el 9% de los clientes, para el Medio se detecta el 21% de los fraudes con el 12.2% de los clientes ambos con densidades o tasas de fraude mayores a la original, para el segmento más bajo tiene una densidad del 1.6%.

# Modelos jerárquicos

En primera instancia, cabe destacar que convertimos a dummys las variables "gender"" y "cardholder".

El Segmento lo definimos como Alto=1, Medio=2 y Bajo=3. 

Asimismo, no se contempló la variable "state" ya que al considerarla en el problema jerárquico hacia que fuera muy complejo su cómputo.


```{r,message=FALSE,warning=FALSE,echo=FALSE}
frax$gender[which(frax$gender==2)]=0
frax$cardholder[which(frax$cardholder==2)]=0
frax$Segmento[which(frax$Segmento=="Alto")]=1
frax$Segmento[which(frax$Segmento=="Medio")]=2
frax$Segmento[which(frax$Segmento=="Bajo")]=3
```

## Modelo beta-bernoulli

El modelo se especificó como sigue:

$$ Y_i \sim Ber(p_{ij}) $$


$$p_j \sim Beta(a,b)  $$
$$a,b \sim gama(0.01,0.01)  $$



```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
# fraude_jerarquico3 <- '
# model
# {
# #Verosimilitud
# for (i in 1:n) {
# 	y[i] ~ dbern(p[seg[i]])
# }
# #Priors 
# for (j in 1:m) { p[j] ~ dbeta(a,b) }
# a ~ dgamma(0.01,0.01)
# b ~ dgamma(0.01,0.01)
# #Predicción
# for (i in 1:n) { yf1[i] ~ dbern(p[seg[i]]) }
# #Parametro de interés
# eta <- a/(a+b)
# }
# '
# cat(fraude_jerarquico3, file = 'fraude_jerarquico3')
# n<-dim(frax)[1]
# m<-length(unique(frax$Segmento))
# 
# #-Defining data-
# data<-list("n"=n,"m"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento)
# 
# #-Defining inits-
# inits<-function(){list(p=rep(0,m),a=1,b=1,yf1=rep(0,n))}
# 
# #-Selecting parameters to monitor-
# parameters<-c("p","eta","yf1")
# 
# 
# modelo_jer3<-jags(data,inits,parameters,model.file="fraude_jerarquico3",
#                 n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

Clasificación global:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
#out.jer3<-modelo_jer3$BUGSoutput$sims.list
# write.csv(out.jer3$alpha,"alpha.jer3.csv")
# write.csv(out.jer3$beta1,"./tablas_parametros/beta1.jer3.csv")
# write.csv(out.jer3$beta2,"./tablas_parametros/beta2.jer3.csv")
# write.csv(out.jer3$beta3,"./tablas_parametros/beta3.jer3.csv")
# write.csv(out.jer3$beta4,"./tablas_parametros/beta4.jer3.csv")
# write.csv(out.jer3$beta5,"./tablas_parametros/beta5.jer3.csv")
# write.csv(out.jer3$beta6,"./tablas_parametros/beta6.jer3.csv")
# write.csv(t(out.jer3$p),"./tablas_parametros/p.jer3.csv")
# write.csv(t(out.jer3$yf1),"./tablas_parametros/yf1.jer3.csv")

out.sum.jer3<-read.csv("./tablas_parametros/summary_jer3.csv")
rownames(out.sum.jer3)<-out.sum.jer3$X
out.sum.jer3<-out.sum.jer3 %>% select(-X)
#out.sum.jer3<-modelo_jer3$BUGSoutput$summary
# write.csv(out.sum.jer3,"summary_jer3.csv")

#Predictions
out.yf.jer3<-out.sum.jer3[grep("yf1",rownames(out.sum.jer3)),]
base_graf.jer3<-as.data.frame(cbind(frax,out.yf.jer3[,c(1,3,7)])) 
kable(prop.table(table(base_graf.jer3$fraudRisk,round(base_graf.jer3$mean)),2))
```


Clasificación por segmento:

Alto:
```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto3<-filter(base_graf.jer3,Segmento==1)
kable(prop.table(table(alto3$fraudRisk,round(alto3$mean)),2))

```

Medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio3<-filter(base_graf.jer3,Segmento==2)
kable(prop.table(table(medio3$fraudRisk,round(medio3$mean)),2))

```

Bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo3<-filter(base_graf.jer3,Segmento==3)
kable(prop.table(table(bajo3$fraudRisk,round(bajo3$mean)),2))
```

Notamos que este modelo da resultados muy malos, pues en términos generales la sensibilidad es del 33%.

Por su parte, para los segmentos medio y bajo no está clasificando ningún fraude, lo cual no es apropiado.

Por lo anterior, no entraremos al análisis de los coeficientes y descartaremos este modelo.


## Modelo lineal generalizado con efectos independientes

El modelo de efectos constantes se especificó de la siguiente forma:


$$ Y_i \sim Ber(p_i) $$


$$ logit(p_i)=\alpha_{ij}+\beta_{1j}genero_{ij}+\beta_{2j}cardholder_{ij}+ \beta_{3j}balance_{ij}+\beta_{4j}numTrans_{ij}+\beta_{5j}numIntTrans_{ij}+\beta_{6j}creditline_{ij} $$


Donde:


$$\alpha_j\sim N(0,0.001) $$

$$\beta_j\sim N(0,0.001) $$





con $j=1, 2, 3$ los segmentos Alto=1, Medio=2 y Bajo=3.


```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
# fraude_jerarquico0 <- '
# model
# {
# #Verosimilitud
# for (i in 1:n){
# 	y[i] ~ dbern(p[i])
# 	logit(p[i])<-alpha[seg[i]]+beta1[seg[i]]*x1[1]+beta2[seg[i]]*x2[i]+beta3[seg[i]]*x3[i]+beta4[seg[i]]*x4[i]+beta5[seg[i]]*x5[i]+beta6[seg[i]]*x6[i]
# }
# #Priors
# for (j in 1:m){
#   alpha[j] ~ dnorm(0,0.001)
#   beta1[j] ~ dnorm(0,0.001)
#   beta2[j] ~ dnorm(0,0.001)
#   beta3[j] ~ dnorm(0,0.001)
#   beta4[j] ~ dnorm(0,0.001)
#   beta5[j] ~ dnorm(0,0.001)
#   beta6[j] ~ dnorm(0,0.001)
# }
# 
# #Predicción
# for (i in 1:n) { yf1[i] ~ dbern(p[i]) }
# 
# }
# '
# cat(fraude_jerarquico0, file = 'fraude_jerarquico0')
# n<-dim(frax)[1]
# m<-length(unique(frax$Segmento))
# 
# #-Defining data-
# data<-list("n"=n,"m"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento,"x1"=frax$gender,"x2"=frax$cardholder,"x3"=frax$balance,"x4"=frax$numTrans,"x5"=frax$numIntlTrans,"x6"=frax$creditLine)
# 
# #-Defining inits-
# inits<-function(){list(alpha=rep(0,m),beta1=rep(0,m),beta2=rep(0,m),beta3=rep(0,m),beta4=rep(0,m),beta5=rep(0,m),beta6=rep(0,m),yf1=rep(1,n))}
# 
# #-Selecting parameters to monitor-
# parameters<-c("p","alpha","beta1","beta2","beta3","beta4","beta5","beta6","yf1")
# 
# 
# modelo_jer0<-jags(data,inits,parameters,model.file="fraude_jerarquico0",
#                 n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

Revisamos que todas las cadenas se estabilizaran y que no hubiera problemas de autocorrelación. 


```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
# Graficas para ver comportamiento de los parametros estimados

#out.jer0<-modelo_jer0$BUGSoutput$sims.list
# write.csv(out.jer0$alpha,"alpha.jer0.csv")
# write.csv(out.jer0$beta1,"./tablas_parametros/beta1.jer0.csv")
# write.csv(out.jer0$beta2,"./tablas_parametros/beta2.jer0.csv")
# write.csv(out.jer0$beta3,"./tablas_parametros/beta3.jer0.csv")
# write.csv(out.jer0$beta4,"./tablas_parametros/beta4.jer0.csv")
# write.csv(out.jer0$beta5,"./tablas_parametros/beta5.jer0.csv")
# write.csv(out.jer0$beta6,"./tablas_parametros/beta6.jer0.csv")
# write.csv(t(out.jer0$p),"./tablas_parametros/p.jer0.csv")
# write.csv(t(out.jer0$yf1),"./tablas_parametros/yf1.jer0.csv")

# #alphas
# alpha.1<-read.csv("./alpha.jer0.csv")
# #alpha.1<-out.jer0$alpha
# colnames(alpha.1)<-c("alpha_Alto","alpha_Medio","alpha_Bajo")
# alpha.1<-as.data.frame(alpha.1)
# 
# 
# graf1<-alpha.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# alpha1.1<-as.data.frame(cbind(1:150,alpha.1))
# colnames(alpha1.1)[1]<-"itera"
# 
# 
# graf2<-alpha1.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("alpha_Alto","alpha_Medio","alpha_Bajo"),labels= c("alpha_Alto","alpha_Medio","alpha_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 
# 
# 
# 
# #beta1
# beta1.1<-read.csv("./tablas_parametros/beta1.jer0.csv") %>% select(-X)
# #beta1.1<-out.jer0$beta1
# colnames(beta1.1)<-c("beta1_Alto","beta1_Medio","beta1_Bajo")
# beta1.1<-as.data.frame(beta1.1)
# 
# 
# graf1<-beta1.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# beta.1.1<-as.data.frame(cbind(1:150,beta1.1))
# colnames(beta.1.1)[1]<-"itera"
# 
# 
# graf2<-beta.1.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("beta1_Alto","beta1_Medio","beta1_Bajo"),labels= c("beta1_Alto","beta1_Medio","beta1_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 
# 
# #beta2
# beta2.1<-read.csv("./tablas_parametros/beta2.jer0.csv")%>% select(-X)
# #beta2.1<-out.jer0$beta2
# colnames(beta2.1)<-c("beta2_Alto","beta2_Medio","beta2_Bajo")
# beta2.1<-as.data.frame(beta2.1)
# 
# 
# graf1<-beta2.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# beta.2.1<-as.data.frame(cbind(1:150,beta2.1))
# colnames(beta.2.1)[1]<-"itera"
# 
# 
# graf2<-beta.2.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("beta2_Alto","beta2_Medio","beta2_Bajo"),labels= c("beta2_Alto","beta2_Medio","beta2_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 
# #beta3
# beta3.1<-read.csv("./tablas_parametros/beta3.jer0.csv")%>% select(-X)
# #beta3.1<-out.jer0$beta3
# colnames(beta3.1)<-c("beta3_Alto","beta3_Medio","beta3_Bajo")
# beta3.1<-as.data.frame(beta3.1)
# 
# 
# graf1<-beta3.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# beta.3.1<-as.data.frame(cbind(1:150,beta3.1))
# colnames(beta.3.1)[1]<-"itera"
# 
# 
# graf2<-beta.3.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("beta3_Alto","beta3_Medio","beta3_Bajo"),labels= c("beta3_Alto","beta3_Medio","beta3_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 
# #beta4
# beta4.1<-read.csv("./tablas_parametros/beta4.jer0.csv")%>% select(-X)
# #beta4.1<-out.jer0$beta4
# colnames(beta4.1)<-c("beta4_Alto","beta4_Medio","beta4_Bajo")
# beta4.1<-as.data.frame(beta4.1)
# 
# 
# graf1<-beta4.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# beta.4.1<-as.data.frame(cbind(1:150,beta4.1))
# colnames(beta.4.1)[1]<-"itera"
# 
# 
# graf2<-beta.4.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("beta4_Alto","beta4_Medio","beta4_Bajo"),labels= c("beta4_Alto","beta4_Medio","beta4_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 
# #beta5
# beta5.1<-read.csv("./tablas_parametros/beta5.jer0.csv")%>% select(-X)
# #beta5.1<-out.jer0$beta5
# colnames(beta5.1)<-c("beta5_Alto","beta5_Medio","beta5_Bajo")
# beta5.1<-as.data.frame(beta5.1)
# 
# 
# graf1<-beta5.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# beta.5.1<-as.data.frame(cbind(1:150,beta5.1))
# colnames(beta.5.1)[1]<-"itera"
# 
# 
# graf2<-beta.5.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("beta5_Alto","beta5_Medio","beta5_Bajo"),labels= c("beta5_Alto","beta5_Medio","beta5_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 
# #beta6
# beta6.1<-read.csv("./tablas_parametros/beta6.jer0.csv")%>% select(-X)
# #beta6.1<-out.jer0$beta6
# colnames(beta6.1)<-c("beta6_Alto","beta6_Medio","beta6_Bajo")
# beta6.1<-as.data.frame(beta6.1)
# 
# 
# graf1<-beta6.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
#   geom_histogram(alpha = .3) +
#   scale_fill_discrete()+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# beta.6.1<-as.data.frame(cbind(1:150,beta6.1))
# colnames(beta.6.1)[1]<-"itera"
# 
# 
# graf2<-beta.6.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
#   scale_fill_discrete(breaks = c("beta6_Alto","beta6_Medio","beta6_Bajo"),labels= c("beta6_Alto","beta6_Medio","beta6_Bajo"))+ theme(legend.position = "bottom")+
#   theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))
# 
# ggarrange(graf1,graf2,ncol=2)
# 

```

A continuación realizamos una tabla para ver que tan bien clasificó los fraudes nuestro modelo:


```{r,message=FALSE,warning=FALSE,echo=FALSE}
out.sum.jer0<-read.csv("./tablas_parametros/summary_jer0.csv")
rownames(out.sum.jer0)<-out.sum.jer0$X
out.sum.jer0<-out.sum.jer0 %>% select(-X)
#out.sum.jer0<-modelo_jer0$BUGSoutput$summary
#write.csv(out.sum.jer0,"summary_jer0.csv")
#Predictions
out.yf.jer0<-out.sum.jer0[grep("yf1",rownames(out.sum.jer0)),]
base_graf.jer0<-as.data.frame(cbind(frax,out.yf.jer0[,c(1,3,7)])) 
kable(prop.table(table(base_graf.jer0$fraudRisk,round(base_graf.jer0$mean)),2))
```

Notamos que la sensibilidad no es de lo más adecuada, pues es del 75%.

Ahora veremos el efecto por cada segmento:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto<-filter(base_graf.jer0,Segmento==1)
kable(prop.table(table(alto$fraudRisk,round(alto$mean)),2))

```

La tabla anterior nos muestra la clasificación para el segmento alto.

Ahora veamos el segmento medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio<-filter(base_graf.jer0,Segmento==2)
kable(prop.table(table(medio$fraudRisk,round(medio$mean)),2))
```

Finalmente, para el segmento bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo<-filter(base_graf.jer0,Segmento==3)
kable(prop.table(table(bajo$fraudRisk,round(bajo$mean)),2))
```

El resultado es el esperado, pues el segmento alto es el que tiene la mejor sensibilidad debido a que es el segmento con mayor número de fraudes, por lo que la clasificación dentro de dicho segmento es más adecuada.

## Modelo lineal generalizado con efectos intercambiables


El modelo lo especificamos como sigue:

$$ Y_i \sim Ber(p_i) $$


$$ logit(p_i)=\alpha_{ij}+\beta_{1j}genero_{ij}+\beta_{2j}cardholder_{ij}+ \beta_{3j}balance_{ij}+\beta_{4j}numTrans_{ij}+\beta_{5j}numIntTrans_{ij}+\beta_{6j}creditline_{ij} $$


Donde:


$$\alpha_j\sim N(0,\tau) $$

$$\beta_j\sim N(0,\tau) $$


$$\tau\sim Gama(0.001,0.001) $$


con $j=1, 2, 3$ los segmentos Alto=1, Medio=2 y Bajo=3.



```{r,message=FALSE,warning=FALSE,echo=FALSE,results="hide",promp=FALSE}
# fraude_jerarquico1 <- '
# model
# {
# #Verosimilitud
# for (i in 1:n){
# 	y[i] ~ dbern(p[i])
# 	logit(p[i])<-alpha[seg[i]]+beta1[seg[i]]*x1[i]+beta2[seg[i]]*x2[i]+beta3[seg[i]]*x3[i]+beta4[seg[i]]*x4[i]+beta5[seg[i]]*x5[i]+beta6[seg[i]]*x6[i]
# }
# #Priors 
# for (j in 1:m){ 
#   alpha[j] ~ dnorm(0,tau)
#   beta1[j] ~ dnorm(0,tau)
#   beta2[j] ~ dnorm(0,tau)
#   beta3[j] ~ dnorm(0,tau)
#   beta4[j] ~ dnorm(0,tau)
#   beta5[j] ~ dnorm(0,tau)
#   beta6[j] ~ dnorm(0,tau)
# }
# # Hyperprior
# tau ~ dgamma(0.001,0.001)
# 
# 
# #Predicción
# for (i in 1:n) { yf1[i] ~ dbern(p[i]) }
# 
# }
# '
# cat(fraude_jerarquico1, file = 'fraude_jerarquico1')
# n<-dim(frax)[1]
# m<-length(unique(frax$Segmento))
# 
# #-Defining data-
# data<-list("n"=n,"m"=m,"y"=frax$fraudRisk,"seg"=frax$Segmento,"x1"=frax$gender,"x2"=frax$cardholder,"x3"=frax$balance,"x4"=frax$numTrans,"x5"=frax$numIntlTrans,"x6"=frax$creditLine)
# 
# #-Defining inits-
# inits<-function(){list(alpha=rep(0,m),beta1=rep(0,m),beta2=rep(0,m),beta3=rep(0,m),beta4=rep(0,m),beta5=rep(0,m),beta6=rep(0,m),a=1,b=1,yf1=rep(1,n))}
# 
# #-Selecting parameters to monitor-
# parameters<-c("p","alpha","beta1","beta2","beta3","beta4","beta5","beta6","yf1")
# 
# 
# modelo_jer1<-jags(data,inits,parameters,model.file="fraude_jerarquico1",
#                 n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

En este caso también las cadenas covergen de forma adecuada aún con pocas iteraciones como se aprecia en las siguientes gráficas para $\alpha_j$ y $\beta_{1j}$



```{r,message=FALSE,warning=FALSE,echo=FALSE}
# Graficas para ver comportamiento de los parametros estimados

#out.jer1<-modelo_jer1$BUGSoutput$sims.list

# write.csv(out.jer1$alpha,"alpha.jer1.csv")
# write.csv(out.jer1$beta1,"./tablas_parametros/beta1.jer1.csv")
# write.csv(out.jer1$beta2,"./tablas_parametros/beta2.jer1.csv")
# write.csv(out.jer1$beta3,"./tablas_parametros/beta3.jer1.csv")
# write.csv(out.jer1$beta4,"./tablas_parametros/beta4.jer1.csv")
# write.csv(out.jer1$beta5,"./tablas_parametros/beta5.jer1.csv")
# write.csv(out.jer1$beta6,"./tablas_parametros/beta6.jer1.csv")
# write.csv(t(out.jer1$p),"./tablas_parametros/p.jer1.csv")
# write.csv(t(out.jer1$yf1),"./tablas_parametros/yf1.jer1.csv")

#alphas
alpha.1<-read.csv("./tablas_parametros/alpha.jer1.csv")%>% select(-X)
#alpha.1<-out.jer1$alpha
colnames(alpha.1)<-c("alpha_Alto","alpha_Medio","alpha_Bajo")
alpha.1<-as.data.frame(alpha.1)


graf1<-alpha.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

alpha1.1<-as.data.frame(cbind(1:150,alpha.1))
colnames(alpha1.1)[1]<-"itera"


graf2<-alpha1.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("alpha_Alto","alpha_Medio","alpha_Bajo"),labels= c("alpha_Alto","alpha_Medio","alpha_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)




#beta1
beta1.1<-read.csv("./tablas_parametros/beta1.jer1.csv")%>% select(-X)
#beta1.1<-out.jer1$beta1
colnames(beta1.1)<-c("beta1_Alto","beta1_Medio","beta1_Bajo")
beta1.1<-as.data.frame(beta1.1)


graf1<-beta1.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

beta.1.1<-as.data.frame(cbind(1:150,beta1.1))
colnames(beta.1.1)[1]<-"itera"


graf2<-beta.1.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("beta1_Alto","beta1_Medio","beta1_Bajo"),labels= c("beta1_Alto","beta1_Medio","beta1_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)


#beta2
beta2.1<-read.csv("./tablas_parametros/beta2.jer1.csv")%>% select(-X)
#beta2.1<-out.jer1$beta2
colnames(beta2.1)<-c("beta2_Alto","beta2_Medio","beta2_Bajo")
beta2.1<-as.data.frame(beta2.1)


graf1<-beta2.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

beta.2.1<-as.data.frame(cbind(1:150,beta2.1))
colnames(beta.2.1)[1]<-"itera"


graf2<-beta.2.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("beta2_Alto","beta2_Medio","beta2_Bajo"),labels= c("beta2_Alto","beta2_Medio","beta2_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)

#beta3
beta3.1<-read.csv("./tablas_parametros/beta3.jer1.csv")%>% select(-X)
#beta3.1<-out.jer1$beta3
colnames(beta3.1)<-c("beta3_Alto","beta3_Medio","beta3_Bajo")
beta3.1<-as.data.frame(beta3.1)


graf1<-beta3.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

beta.3.1<-as.data.frame(cbind(1:150,beta3.1))
colnames(beta.3.1)[1]<-"itera"


graf2<-beta.3.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("beta3_Alto","beta3_Medio","beta3_Bajo"),labels= c("beta3_Alto","beta3_Medio","beta3_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)

#beta4
beta4.1<-read.csv("./tablas_parametros/beta4.jer1.csv")%>% select(-X)
#beta4.1<-out.jer1$beta4
colnames(beta4.1)<-c("beta4_Alto","beta4_Medio","beta4_Bajo")
beta4.1<-as.data.frame(beta4.1)


graf1<-beta4.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

beta.4.1<-as.data.frame(cbind(1:150,beta4.1))
colnames(beta.4.1)[1]<-"itera"


graf2<-beta.4.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("beta4_Alto","beta4_Medio","beta4_Bajo"),labels= c("beta4_Alto","beta4_Medio","beta4_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)

#beta5
beta5.1<-read.csv("./tablas_parametros/beta5.jer1.csv")%>% select(-X)
#beta5.1<-out.jer1$beta5
colnames(beta5.1)<-c("beta5_Alto","beta5_Medio","beta5_Bajo")
beta5.1<-as.data.frame(beta5.1)


graf1<-beta5.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

beta.5.1<-as.data.frame(cbind(1:150,beta5.1))
colnames(beta.5.1)[1]<-"itera"


graf2<-beta.5.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("beta5_Alto","beta5_Medio","beta5_Bajo"),labels= c("beta5_Alto","beta5_Medio","beta5_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)

#beta6
beta6.1<-read.csv("./tablas_parametros/beta6.jer1.csv")%>% select(-X)
#beta6.1<-out.jer1$beta6
colnames(beta6.1)<-c("beta6_Alto","beta6_Medio","beta6_Bajo")
beta6.1<-as.data.frame(beta6.1)


graf1<-beta6.1%>% gather() %>% ggplot(aes(x = value, fill = key)) +
  geom_histogram(alpha = .3) +
  scale_fill_discrete()+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

beta.6.1<-as.data.frame(cbind(1:150,beta6.1))
colnames(beta.6.1)[1]<-"itera"


graf2<-beta.6.1 %>% gather("parametro_segmento","valor",2:4) %>% ggplot(aes(x=itera,y=valor,color=parametro_segmento)) + geom_line(alpha=0.6)+
  scale_fill_discrete(breaks = c("beta6_Alto","beta6_Medio","beta6_Bajo"),labels= c("beta6_Alto","beta6_Medio","beta6_Bajo"))+ theme(legend.position = "bottom")+
  theme(legend.title=element_blank())+theme(legend.text= element_text(size=7))

ggarrange(graf1,graf2,ncol=2)



```
Notamos que todos los parámetros son significativos pues en sus intervalos al 95% no contienen al cero.

Por otro lado, notamos que la diferencia de grupos se aprecia principalmente en las variables cardholder y balance. En menor medida se aprecia dicha diferenciación en las variables numTrans, numIntTrans y creditLine.


De igual manera realizamos una tabla para la clasificación:


```{r,message=FALSE,warning=FALSE,echo=FALSE}

out.sum.jer1<-read.csv("./tablas_parametros/summary_jer1.csv")
rownames(out.sum.jer1)<-out.sum.jer1$X
out.sum.jer1<-out.sum.jer1 %>% select(-X)
#out.sum.jer1<-modelo_jer1$BUGSoutput$summary
#write.csv(out.sum.jer1,"summary_jer1.csv")

#Predictions
out.yf.jer1<-out.sum.jer1[grep("yf1",rownames(out.sum.jer1)),]
base_graf.jer1<-as.data.frame(cbind(frax,out.yf.jer1[,c(1,3,7)])) 
kable(prop.table(table(base_graf.jer1$fraudRisk,round(base_graf.jer1$mean)),2))
```

Notamos resultados muy similares al de efectos independientes; es decir, que nuestro modelo tiene una especificidad alta; no obstante, la sensibilidad de 75% es baja, pues el efecto de tener un fraude es muy relevante.

Ahora analizaremos la clasificación por cada segmento. Primero se muestra el segmento alto:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto1<-filter(base_graf.jer1,Segmento==1)
kable(prop.table(table(alto1$fraudRisk,round(alto1$mean)),2))

```

Ahora veamos el segmento medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio1<-filter(base_graf.jer1,Segmento==2)
kable(prop.table(table(medio1$fraudRisk,round(medio1$mean)),2))
```

Finalmente, para el segmento bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo1<-filter(base_graf.jer1,Segmento==3)
kable(prop.table(table(bajo1$fraudRisk,round(bajo1$mean)),2))
```

El resultado anterior nuevamente resulta consistente, pues sabemos que en la categoría Alta al haber más fraudes, la predicción va a ser mejor. Por su parte, en las otras dos categorías como el porcentaje de fraudes es menor, no hay suficientes "éxitos" para generar una buena predicción.

Como constatamos el modelo de efectos independientes y el de intercambiabilidad que "comparte" la mayor cantidad de información entre segmentos arrojan resultados muy parecidos. 



#Hipótesis e interpretación de los modelos

Como el modelo de efectos independientes y el de intercambiabilidad son muy similares, en esta sección utilizamos solamente el segundo. 

La primer hipótesis es que las personas con un número alto de transacciones (numTrans y numIntTrans) tienen mayor propensión a sufrir un fraude. De ser el caso se esperaría que los parámetros relacionados con estas dos variables sean distintos para cada segmento. El parámetro $\beta_4$ corresponde a numTrans y $\beta_5$ a numIntlTrans. 

```{r,message=FALSE,warning=FALSE,echo=FALSE}

kable(out.sum.jer1[c(1:3, 13:18),c(1,3,7)])

```

En el caso de las transacciones internacionales, el parámetro es distinto entre los segmentos, especialmente para el segmento alto. Los intervalos de confianza se empalman solamente en los valores altos pero hay diferencia entre estos. Estas características nos sugieren que en efecto el número de transacciones internacionales impacta en el número de fraudes diferenciando al segmento alto de los otros dos. 

Por su parte, las transacciones domésticas $\beta_4$ tienen un efecto mayor en el segmento medio que en los otros dos. El efecto más débil es para el segmento alto. Considerando los intervalos de confianza podemos concluir que las diferencias de estos efectos entre un segmento y otro son menores que para las transacciones internacionales. 

En la segunda hipótesis se plantea que las mujeres tienen una mayor predisposición al fraude que los hombres. El parámetro asociado es $\beta_1$ y la variable dummy es 0 para mujeres y 1 para hombres.


```{r,message=FALSE,warning=FALSE,echo=FALSE}

kable(out.sum.jer1[1:6,c(1,3,7)])

```

En los tres segmentos el parámetro es negativo indicando que si el cliente es hombre el valor estimado de fraude disminuye respecto a una mujer. En el segmento bajo la disminución es menor y para el segmento medio es la más alta. Esto confirma la hipótesis pues las mujeres obtienen valores más altos en el modelo. Los intervalos de confianza son similares y el efecto de esta variable en los segmentos es similar. 

La tercer hipótesis es que los titulares de las tarjetas son más propensas a fraude que las adicionales. El párametro asociado es $\beta_2$ y como vemos en el primer segmento es positivo y en los demás negativo. 


```{r,message=FALSE,warning=FALSE,echo=FALSE}

kable(out.sum.jer1[c(1:3,7:9),c(1,3,7)])

```

A diferencia de la variable género, en este caso  el efecto de la variable en la estimación del fraude tiene distinto signo en los segmentos. Esto nos indica que si la tarjeta es del titular, el valor estimado de fraude aumenta en el primer segmento pero disminuye en los otros dos. Es importante considerar los intervalos de confianza pues en el segmento alto el parámetro no es significativo. Además, este parámetro podría ser negativo y la conclusión se modificaría. Para el segmento medio y el bajo los intervalos de confianza son muy similares indicando que el efecto de la titularidad de la tarjeta es similar en ambos segmentos. 



# Predicción

Finalmente, para realizar las predicciones segmentaremos la muestra en 70% para entrenamiento y 30% para prueba y utilizaremos el modelo con efectos intercambiables.

```{r,message=FALSE,warning=FALSE,echo=FALSE}
trainIndex <- createDataPartition(frax$fraudRisk, p = .7, list = FALSE, times = 1)
fraxTrain <- frax[ trainIndex,]
fraxTest  <- frax[-trainIndex,]


# fraude_prediccion <- '
# model
# {
# #Verosimilitud
# for (i in 1:n){
# 	y[i] ~ dbern(p[i])
# 	logit(p[i])<-alpha[seg[i]]+beta1[seg[i]]*x1[i]+beta2[seg[i]]*x2[i]+beta3[seg[i]]*x3[i]+beta4[seg[i]]*x4[i]+beta5[seg[i]]*x5[i]+beta6[seg[i]]*x6[i]
# }
# #Priors
# for (j in 1:m){
#   alpha[j] ~ dnorm(0,tau)
#   beta1[j] ~ dnorm(0,tau)
#   beta2[j] ~ dnorm(0,tau)
#   beta3[j] ~ dnorm(0,tau)
#   beta4[j] ~ dnorm(0,tau)
#   beta5[j] ~ dnorm(0,tau)
#   beta6[j] ~ dnorm(0,tau)
# }
# # Hyperprior
# tau ~ dgamma(0.001,0.001)
# 
# 
# #Predicción
# for (i in 1:k){
# 	yf2[i] ~ dbern(pf[i])
# 	logit(pf[i])<-alpha[seg[i]]+beta1[seg[i]]*x1f[i]+beta2[seg[i]]*x2f[i]+beta3[seg[i]]*x3f[i]+beta4[seg[i]]*x4f[i]+beta5[seg[i]]*x5f[i]+beta6[seg[i]]*x6f[i]
# }
# }
# '
# cat(fraude_prediccion, file = 'fraude_prediccion')
# n<-dim(fraxTrain)[1]
# m<-length(unique(frax$Segmento))
# k<-dim(fraxTest)[1]
# 
# #-Defining data-
# data<-list("n"=n,"m"=m,"k"=k,"y"=fraxTrain$fraudRisk,"seg"=fraxTrain$Segmento,"x1"=fraxTrain$gender,"x2"=fraxTrain$cardholder,"x3"=fraxTrain$balance,"x4"=fraxTrain$numTrans,"x5"=fraxTrain$numIntlTrans,"x6"=fraxTrain$creditLine,"x1f"=fraxTest$gender,"x2f"=fraxTest$cardholder,"x3f"=fraxTest$balance,"x4f"=fraxTest$numTrans,"x5f"=fraxTest$numIntlTrans,"x6f"=fraxTest$creditLine)
# 
# #-Defining inits-
# inits<-function(){list(alpha=rep(0,m),beta1=rep(0,m),beta2=rep(0,m),beta3=rep(0,m),beta4=rep(0,m),beta5=rep(0,m),beta6=rep(0,m),a=1,b=1,yf2=rep(1,k))}
# 
# #-Selecting parameters to monitor-
# parameters<-c("pf","alpha","beta1","beta2","beta3","beta4","beta5","beta6","yf2")
# 
# 
# modelo_jer_pred<-jags(data,inits,parameters,model.file="fraude_prediccion",
#                 n.iter=200,n.chains=1,n.burnin=50,n.thin = 1)

```

```{r,message=FALSE,warning=FALSE,echo=FALSE}
out.sum.pred<-read.csv("./tablas_parametros/summary_jer_pred.csv")
rownames(out.sum.pred)<-out.sum.pred$X
out.sum.pred<-out.sum.pred %>% select(-X)
#out.sum.pred<-modelo_jer_pred$BUGSoutput$summary
#write.csv(out.sum.pred,"summary_jer_pred.csv")

#Predictions
out.yf.pred<-out.sum.pred[grep("yf2",rownames(out.sum.pred)),]
base_graf.pred<-as.data.frame(cbind(fraxTest,out.yf.pred[,c(1,3,7)])) 
kable(prop.table(table(base_graf.pred$fraudRisk,round(base_graf.pred$mean)),2))
```

Notamos que las predicciones realizadas con el modelo jerárquico lineal generalizado con efectos intercambiabes es bastante bueno, pues tiene un precisión del 96% y una sensibilidad del 78%.

Ahora analizaremos las predicciones en cada uno de los segmentos:

Alto:
```{r,message=FALSE,warning=FALSE,echo=FALSE}
alto3<-filter(base_graf.pred,Segmento==1)
kable(prop.table(table(alto3$fraudRisk,round(alto3$mean)),2))

```

En el segmento alto, el modelo arroja muy buenas predicciones, logrando una sensibilidad del 80%

Medio:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
medio3<-filter(base_graf.pred,Segmento==2)
kable(prop.table(table(medio3$fraudRisk,round(medio3$mean)),2))

```

El el segmento medio es donde se tiene la peor predicción, lo que se podría atribuir a que en este segmento hay un menor número de observaciones.

Bajo:

```{r,message=FALSE,warning=FALSE,echo=FALSE}
bajo3<-filter(base_graf.pred,Segmento==3)
kable(prop.table(table(bajo3$fraudRisk,round(bajo3$mean)),2))
```

Finalmente, como el segmento bajo tuvo una predicción aceptable con una precisión del 98% y una sensibilidad del 74%.


# Conclusiones

La detección de fraude es díficil por el bajo número de ocurrencias. La proporción de fraude en los datos analizados es apróximadamente 6.6%. A partir de las variables balance y línea de crédito se generaron tres segmentos de nivel de fraude. El segmento alto concentra casi el 58% de los fraudes y en este es más fácil detectarlos. El segmento medio y el bajo tienen cerca de 20% de los fraudes cada uno pero el segmento medio tiene menos clientes por lo que su detección es más sencilla. 

Tomando en cuenta los segmentos y el resto de las variables (excluyendo estado) se construyeron tres modelos. El primero es un modelo beta-bernoulli pero los resultados obtenidos no son buenos (sensibilidad de 33%). El segundo modelo es generalizado con efectos independientes y el tercero es un modelo generalizado con efectos intercambiables. Ambos convergen y arrojan resultados similares (sensibilidad cercana a 75%) y se seleccionó el modelo de efectos intercambiables. 

De acuerdo con el modelo generalizado de efectos intercambiables las variables número de transacciones internacionales y titularidad de la tarjeta tienen parámetros distintos para los segmentos, especialmente el alto. Por su parte las variables número de transacciones domésticas y género no diferencían entre los segmentos. Con esta información podemos concluir que aquellos clientes del segmento alto titulares de la tarjeta y con alto número de transacciones internacionales son más propensos a fraude. 

Las predicciones obtenidas con el modelo son muy buenas, logrando en general una precisión del 96% y una sensibilidad del 98%. La mejor predicción se obtuvo en el segmento "Alto", alcanzando una sensibilidad del 80% y la peor predicción se obtuvo en el segmento "Medio" con una precisión del 68%, lo cual se podría atribuir a que este segmento es el que tiene el menor número de observaciones.

# Referencias

- Notas de clase del profesor Juan Carlos Martínez Ovando, en particular lo referente a modelos jerárquicos y modelos de regresión.

- Gelman, A., Carlin, J. B., Stern, H. S. & Rubin, D. Bayesian Data Analysis, 2002, 2a edición. Chapman & Hall: Boca Raton. 

- Gelman, A., Hill, J. Data Analysis Using Regression and Multilevel / Hierarchical Models, 2008, 6a edición, Cambridge University Press. 
